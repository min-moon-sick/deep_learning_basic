{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790d8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3aa9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['배가', '너무', '고프다']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '배가 너무 고프다'\n",
    "result = text_to_word_sequence(text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df59915",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "        '먼저 텍스트의 각 단어를 나누어 토큰화합니다.',\n",
    "       '텍스트의 단어를 토큰화해야 딥러닝에서 인식됩니다.',\n",
    "       '토큰화 한 결과는 딥러닝에서 사용할 수 있습니다.'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "421de682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 2), ('나누어', 1), ('토큰화합니다', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화', 1), ('한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n"
     ]
    }
   ],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)\n",
    "print(token.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980f0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
